{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610b9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of textract: .* suffix can only be used with `==` or `!=` operators\n",
      "    extract-msg (<=0.29.*)\n",
      "                 ~~~~~~~^\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f53a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: glob2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of textract: .* suffix can only be used with `==` or `!=` operators\n",
      "    extract-msg (<=0.29.*)\n",
      "                 ~~~~~~~^\n"
     ]
    }
   ],
   "source": [
    "%pip install glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb40c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages are imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "print(\"packages are imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c94e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory: csv_outputs\n",
      "Output directory: cleaned_csv\n",
      "Combined output directory: combined_csv\n",
      "Configuration completed successfully\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "INPUT_CSV_DIRECTORY = \"csv_outputs\"          \n",
    "OUTPUT_DIRECTORY = \"cleaned_csv\"             \n",
    "COMBINED_OUTPUT_DIR = \"combined_csv\"         \n",
    "\n",
    "# define headers and their variations (coming from the docx extraction)\n",
    "HEADER_MAPPING = {\n",
    "    \"Week\": [\n",
    "        \"Week\", \"Week No\", \"Week #\", \"Week Number\", \"Week/Date\"\n",
    "    ],\n",
    "    \"Learning Outcomes\": [\n",
    "        \"Learning Outcomes\", \"Learning Outcome\", \"Learning\\\\nOutcomes\",\n",
    "        \"Learning Outcomes (LO) / Learner and Learning Outcomes (LLO)\",\n",
    "        \"Learning Outcomes\\\\n(At the end of the session, students are expected to:)\",\n",
    "        \"Learning Outcomes\\\\n(At the end of the session, students are expected to :)\",\n",
    "        \"Learning\\\\nOutcomes\", \"Learning \\\\nOutcomes\"\n",
    "    ],\n",
    "    \"Deliverables\": [\n",
    "        \"Deliverables Outcomes\", \"Deliverables/Outcomes\", \"Deliverables\", \n",
    "        \"Deliverables/\\\\nOutcomes\", \"Deliverables\\\\n/ Outcomes\", \"Deliverables/ Outcomes\",\n",
    "        \"Deliverables/\\\\xa0 Outcomes\", \"Deliverables/\\\\xa0\\\\nOutcomes\", \n",
    "        \"Deliverable / Outcomes\", \"Deliverables\\\\n/ Outcomes/Rubrics\"\n",
    "    ],\n",
    "    \"Assessments\": [\n",
    "        \"Assessments\", \"Assessment\", \"Assessment Task\", \"Assessment\\\\n/ Output\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# create output directories \n",
    "os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(COMBINED_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Input directory: {INPUT_CSV_DIRECTORY}\")\n",
    "print(f\"Output directory: {OUTPUT_DIRECTORY}\")\n",
    "print(f\"Combined output directory: {COMBINED_OUTPUT_DIR}\")\n",
    "print(\"Configuration completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "400707fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "def normalize_header(text):\n",
    "    \"\"\"\n",
    "    Normalize header text: lowercase, remove spaces, slashes, punctuation.\n",
    "    Same logic as your DOCX extraction script.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-z0-9]', '', text.lower())\n",
    "\n",
    "def find_csv_files(directory):\n",
    "    \"\"\"Find all CSV files in the specified directory.\"\"\"\n",
    "    csv_pattern = os.path.join(directory, \"*.csv\")\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    return csv_files\n",
    "\n",
    "def match_headers_to_canonical(df_headers, header_mapping):\n",
    "    \"\"\"\n",
    "    Match DataFrame headers to canonical headers using substring matching.\n",
    "    Returns matched canonical headers, column indices, and final header names.\n",
    "    \"\"\"\n",
    "    matched_canonical_headers = []\n",
    "    col_indices = []\n",
    "    final_headers = []\n",
    "    \n",
    "    # Normalize input headers\n",
    "    normalized_df_headers = [normalize_header(h) for h in df_headers]\n",
    "    \n",
    "    for canonical_header, possible_variations in header_mapping.items():\n",
    "        found_variation_index = -1\n",
    "        \n",
    "        # Check if any variation matches as substring\n",
    "        for variation in possible_variations:\n",
    "            normalized_variation = normalize_header(variation)\n",
    "            \n",
    "            for j, normalized_table_header in enumerate(normalized_df_headers):\n",
    "                if normalized_variation in normalized_table_header or normalized_table_header in normalized_variation:\n",
    "                    found_variation_index = j\n",
    "                    break\n",
    "                    \n",
    "            if found_variation_index != -1:\n",
    "                break\n",
    "        \n",
    "        if found_variation_index != -1:\n",
    "            col_indices.append(found_variation_index)\n",
    "            final_headers.append(canonical_header)\n",
    "            matched_canonical_headers.append(canonical_header)\n",
    "            \n",
    "    return matched_canonical_headers, col_indices, final_headers\n",
    "\n",
    "def clean_text_data(df):\n",
    "    \"\"\"Clean text data removing common DOCX extraction artifacts.\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    for col in df_clean.columns:\n",
    "        if df_clean[col].dtype == 'object':\n",
    "            # Strip whitespace\n",
    "            df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "            \n",
    "            # Replace 'nan' string with empty string\n",
    "            df_clean[col] = df_clean[col].replace(['nan', 'NaN'], '')\n",
    "            \n",
    "            # Clean up common formatting issues from DOCX extraction\n",
    "            df_clean[col] = df_clean[col].str.replace('\\\\n', ' ', regex=False)\n",
    "            df_clean[col] = df_clean[col].str.replace('\\\\xa0', ' ', regex=False)\n",
    "            df_clean[col] = df_clean[col].str.replace('  +', ' ', regex=True)  # Multiple spaces to single\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "print(\"functions defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fc1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 57 CSV files...\n",
      "============================================================\n",
      "Processing: AUTOMAT_SYLLABUS_2ndTerm_2024_ver3.0.csv\n",
      "  Original shape: (10, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 6)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "Processing: CLDCOMP_Syllabus 2023-2024.csv\n",
      "  Original shape: (11, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 6)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "Processing: CLDSRV2_Syllabus 2023_2024.csv\n",
      "  Original shape: (5, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (5, 6)\n",
      "  Successfully processed\n",
      "  Success: 5 rows extracted\n",
      "Processing: CLDSRV2_Syllabus_2024.csv\n",
      "  Original shape: (10, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 6)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "Processing: COMPORG_SYLLABUS_AY2024_2025.csv\n",
      "  Original shape: (11, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 6)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "Processing: COMSEC2_Syllabus_2024.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: COMSEC3_Syllabus_2024 - 2025.csv\n",
      "  Original shape: (9, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (9, 6)\n",
      "  Successfully processed\n",
      "  Success: 9 rows extracted\n",
      "Processing: COMSECT_Syllabus_2024.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: Course Syllabus PHYSICS1 Natural Physics 1 for IT.csv\n",
      "  Original shape: (10, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 6)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "Processing: Course Syllabus PHYSICS2 Natural Physics 2 for IT.csv\n",
      "  Original shape: (10, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 6)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "Processing: CRISKMA Syllabus AY 2024 - 2025.csv\n",
      "  Original shape: (7, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (7, 6)\n",
      "  Successfully processed\n",
      "  Success: 7 rows extracted\n",
      "Processing: CSPROJ2 Course Syllabus AY2024-2025 (KRC)v.03.csv\n",
      "  Original shape: (1, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (1, 6)\n",
      "  Successfully processed\n",
      "  Success: 1 rows extracted\n",
      "Processing: DASTRUC_Syllabus T1 AY 2024-2025 Revise version.csv\n",
      "  Original shape: (11, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 6)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "Processing: DATAMA1_SYLLABUS_2024_1st_term_Version.csv\n",
      "  Original shape: (11, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 6)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "Processing: DATAMA1_SYLLABUS_Ver3.0_2023.csv\n",
      "  Original shape: (11, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 6)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "Processing: DATAMA2_SYLLABUS_1st_Term_2024_version.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (12, 6)\n",
      "  Successfully processed\n",
      "  Success: 12 rows extracted\n",
      "Processing: DATAMA2_SYLLABUS_2nd_Term_2024_version3.0.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (12, 6)\n",
      "  Successfully processed\n",
      "  Success: 12 rows extracted\n",
      "Processing: DESALGO_Syllabus_2024.csv\n",
      "  Original shape: (7, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (7, 6)\n",
      "  Successfully processed\n",
      "  Success: 7 rows extracted\n",
      "Processing: ENTJAVA (Using C# .NET) Course Syllabus 2023-2024.csv\n",
      "  Original shape: (11, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 6)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "Processing: ICTSRV1_Syllabus_2024.csv\n",
      "  Original shape: (15, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (15, 6)\n",
      "  Successfully processed\n",
      "  Success: 15 rows extracted\n",
      "Processing: INFOSEC_Syllabus_2023.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: INFOSEC_Syllabus_T1_AY_2024_2025.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: INPROLA Syllabus 2ndTerm_2024ver3.0.csv\n",
      "  Original shape: (8, 3)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Final shape: (8, 6)\n",
      "  Successfully processed\n",
      "  Success: 8 rows extracted\n",
      "Processing: INPROLA Syllabus Revision T1 A.Y. 2023 Revise Oct 2023.csv\n",
      "  Original shape: (9, 3)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Final shape: (9, 6)\n",
      "  Successfully processed\n",
      "  Success: 9 rows extracted\n",
      "Processing: INPROLA Syllabus T1 A.Y. 2024-2025 Revise version.csv\n",
      "  Original shape: (18, 3)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Final shape: (18, 6)\n",
      "  Successfully processed\n",
      "  Success: 18 rows extracted\n",
      "Processing: INTCOMC_Syllabus 2024-2025.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: INTSDEV_Syllabus_2023-2024.csv\n",
      "  Original shape: (7, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (7, 6)\n",
      "  Successfully processed\n",
      "  Success: 7 rows extracted\n",
      "Processing: ITCONCE_SYLLABUS_AY2023-2024 - Revise Oct 2023.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: MCSPROJ Course Syllabus AY2024-2025 for IT.csv\n",
      "  Original shape: (3, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (3, 6)\n",
      "  Successfully processed\n",
      "  Success: 3 rows extracted\n",
      "Processing: MNSYSIT Course Syllabus AY 2024-2025.csv\n",
      "  Original shape: (4, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (4, 6)\n",
      "  Successfully processed\n",
      "  Success: 4 rows extracted\n",
      "Processing: MNSYSIT Salesforce_AY 2023-2024 v2.csv\n",
      "  Original shape: (4, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (4, 6)\n",
      "  Successfully processed\n",
      "  Success: 4 rows extracted\n",
      "Processing: MNSYSIT Salesforce_T1 AY 2024-2025 for upload.csv\n",
      "  Original shape: (2, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (2, 6)\n",
      "  Successfully processed\n",
      "  Success: 2 rows extracted\n",
      "Processing: MNTSDEV-SNTSDEV-INTSDEV Course Syllabus 2023 - 2024.csv\n",
      "  Original shape: (7, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (7, 6)\n",
      "  Successfully processed\n",
      "  Success: 7 rows extracted\n",
      "Processing: MNTSDEV-SNTSDEV-INTSDEV Course Syllabus AY 2024 - 2025 v2.csv\n",
      "  Original shape: (6, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (6, 6)\n",
      "  Successfully processed\n",
      "  Success: 6 rows extracted\n",
      "Processing: MOBAPPL  Syllabus T2 A.Y. 2024-2025 Revise version.csv\n",
      "  Original shape: (14, 3)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Final shape: (14, 6)\n",
      "  Successfully processed\n",
      "  Success: 14 rows extracted\n",
      "Processing: MOBPROG Course Syllabus 1T 2022 - Revise Oct 2023.csv\n",
      "  Original shape: (16, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (16, 6)\n",
      "  Successfully processed\n",
      "  Success: 16 rows extracted\n",
      "Processing: MOBPROG Course Syllabus 1T 2024-2025 Revise version.csv\n",
      "  Original shape: (16, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (16, 6)\n",
      "  Successfully processed\n",
      "  Success: 16 rows extracted\n",
      "Processing: MODESIM_Syllabus_2024.csv\n",
      "  Original shape: (11, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 6)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "Processing: NETDESM_2024.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: OPESYST_SYLLABUS_AY2024-2025.csv\n",
      "  Original shape: (19, 3)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Final shape: (19, 6)\n",
      "  Successfully processed\n",
      "  Success: 19 rows extracted\n",
      "Processing: PROGCON Syllabus Revision  T1 A.Y. 2023-2024 Revise Oct 2023.csv\n",
      "  Original shape: (15, 3)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Assessments']\n",
      "  Final shape: (15, 6)\n",
      "  Successfully processed\n",
      "  Success: 15 rows extracted\n",
      "Processing: PROGCON_SYLLABUS_2024_1stTerm_version.csv\n",
      "  Original shape: (9, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (9, 6)\n",
      "  Successfully processed\n",
      "  Success: 9 rows extracted\n",
      "Processing: PROGCON_SYLLABUS_2ndTerm_2024_3.0.csv\n",
      "  Original shape: (9, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (9, 6)\n",
      "  Successfully processed\n",
      "  Success: 9 rows extracted\n",
      "Processing: PROJMAN AY 2023_2024 Syllabus.csv\n",
      "  Original shape: (10, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 6)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "Processing: PROJMAN _Syllabus_T1 AY 2024-2025.csv\n",
      "  Original shape: (14, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (14, 6)\n",
      "  Successfully processed\n",
      "  Success: 14 rows extracted\n",
      "Processing: QUALITY_SYLLABUS_2023 for CS.csv\n",
      "  Original shape: (12, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (12, 6)\n",
      "  Successfully processed\n",
      "  Success: 12 rows extracted\n",
      "Processing: QUALITY_SYLLABUS_AY_2023_2024 for IT.csv\n",
      "  Original shape: (12, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (12, 6)\n",
      "  Successfully processed\n",
      "  Success: 12 rows extracted\n",
      "Processing: SCSPROJ - MCSPROJ Course Syllabus AY 2023 - 2024.csv\n",
      "  Original shape: (3, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (3, 6)\n",
      "  Successfully processed\n",
      "  Success: 3 rows extracted\n",
      "Processing: SCSPROJ Course Syllabus AY2024-2025 for CS.csv\n",
      "  Original shape: (3, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (3, 6)\n",
      "  Successfully processed\n",
      "  Success: 3 rows extracted\n",
      "Processing: Softdev Syllabus 2023 - 2024 for CS and IT.csv\n",
      "  Original shape: (10, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 6)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "Processing: SOFTDEV_Syllabus_T1_AY_ 2024_2025_for_CS_and _T.csv\n",
      "  Original shape: (10, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 6)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "Processing: SSYADD1-MSYADD1_Syllabus_2023.csv\n",
      "  Original shape: (6, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (6, 6)\n",
      "  Successfully processed\n",
      "  Success: 6 rows extracted\n",
      "Processing: SSYADD1-MSYADD1_Syllabus_T1 AY 2024-2025.csv\n",
      "  Original shape: (14, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (14, 6)\n",
      "  Successfully processed\n",
      "  Success: 14 rows extracted\n",
      "Processing: THESIS2 2023 Syllabus  T1 AY 2024 2025.csv\n",
      "  Original shape: (10, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 6)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "Processing: USERDES Course Syllabus 1T 2020.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: WEBPROG_Syllabus_2023_2024.csv\n",
      "  Original shape: (14, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "Processing: WEBPSEC_Syllabus_2024.csv\n",
      "  Original shape: (13, 4)\n",
      "  Original headers: ['Week', 'Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 6)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "============================================================\n",
      "  Processing Summary:\n",
      "  Total files: 57\n",
      "  Successfully processed: 57\n",
      "  Failed: 0\n",
      "  Total rows extracted: 585\n",
      "\n",
      "Individual processing completed\n"
     ]
    }
   ],
   "source": [
    "def process_single_csv(file_path, header_mapping, add_source_info=True):\n",
    "    \"\"\"Process a single CSV file and extract target columns.\"\"\"\n",
    "    try:\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        # read CSV with encoding handling\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='latin-1')\n",
    "                print(f\"  Used latin-1 encoding\")\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(file_path, encoding='cp1252')\n",
    "                print(f\"  Used cp1252 encoding\")\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"  Warning: Empty file\")\n",
    "            return None # return None for empty files\n",
    "\n",
    "        print(f\"  Original shape: {df.shape}\")\n",
    "        print(f\"  Original headers: {list(df.columns)}\")\n",
    "\n",
    "        # match headers to canonical ones\n",
    "        df_headers = list(df.columns)\n",
    "        matched_canonical_headers, col_indices, final_headers = match_headers_to_canonical(df_headers, header_mapping)\n",
    "\n",
    "        # removed the check for len(matched_canonical_headers) < 2\n",
    "        # the function will now attempt to process even if fewer than 2 headers are matched.\n",
    "\n",
    "        print(f\"  Matched canonical headers: {matched_canonical_headers}\")\n",
    "\n",
    "        # extract the relevant columns\n",
    "        selected_columns = [df.columns[i] for i in col_indices]\n",
    "        extracted_df = df[selected_columns].copy()\n",
    "\n",
    "        # rename columns to canonical names\n",
    "        column_rename_map = dict(zip(selected_columns, final_headers))\n",
    "        extracted_df.rename(columns=column_rename_map, inplace=True)\n",
    "\n",
    "        # add any additional processing steps here\n",
    "        for canonical_header, variations in header_mapping.items():\n",
    "            if canonical_header not in extracted_df.columns:\n",
    "                for col in extracted_df.columns:\n",
    "                    for variation in variations:\n",
    "                        if normalize_header(col) == normalize_header(variation):\n",
    "                            extracted_df[canonical_header] = extracted_df[col]\n",
    "                            break\n",
    "                    if canonical_header in extracted_df.columns:\n",
    "                        break\n",
    "\n",
    "        # ensure all canonical columns exist and reorder columns - # This part is modified\n",
    "        # ensure all four canonical columns exist and reorder columns accordingly\n",
    "        all_canonical_headers = [\"Week\", \"Learning Outcomes\", \"Deliverables\", \"Assessments\"]\n",
    "        for canonical_header in all_canonical_headers:\n",
    "            if canonical_header not in extracted_df.columns:\n",
    "                extracted_df[canonical_header] = \"\"\n",
    "\n",
    "        # reorder columns\n",
    "        # ensure all four canonical headers are used for reordering\n",
    "        extracted_df = extracted_df[all_canonical_headers]\n",
    "\n",
    "        # clean the data\n",
    "        cleaned_df = clean_text_data(extracted_df)\n",
    "\n",
    "        # remove completely empty rows\n",
    "        cleaned_df = cleaned_df.dropna(how='all')\n",
    "\n",
    "        # ensure all target columns are string type before using .str methods\n",
    "        for col in [\"Week\", \"Learning Outcomes\", \"Deliverables\", \"Assessments\"]:\n",
    "            if col in cleaned_df.columns:\n",
    "                cleaned_df[col] = cleaned_df[col].astype(str)\n",
    "                \n",
    "        # remove rows where all target columns are empty\n",
    "        mask = (cleaned_df['Week'].str.len() > 0) | \\\n",
    "               (cleaned_df['Learning Outcomes'].str.len() > 0) | \\\n",
    "               (cleaned_df['Deliverables'].str.len() > 0) | \\\n",
    "               (cleaned_df['Assessments'].str.len() > 0)\n",
    "        cleaned_df = cleaned_df[mask]\n",
    "\n",
    "        # add source information if requested\n",
    "        if add_source_info:\n",
    "            cleaned_df['Source_File'] = filename\n",
    "\n",
    "            # extract course code from filename\n",
    "            course_match = re.match(r'^([A-Z]+[0-9]*)', filename)\n",
    "            if course_match:\n",
    "                cleaned_df['Course_Code'] = course_match.group(1)\n",
    "            else:\n",
    "                cleaned_df['Course_Code'] = ''\n",
    "\n",
    "        # reset index\n",
    "        cleaned_df = cleaned_df.reset_index(drop=True)\n",
    "\n",
    "        print(f\"  Final shape: {cleaned_df.shape}\")\n",
    "        print(f\"  Successfully processed\")\n",
    "\n",
    "        return cleaned_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {os.path.basename(file_path)}: {str(e)}\")\n",
    "        # return None in case of unexpected errors during processing\n",
    "        return None\n",
    "\n",
    "\n",
    "# process all CSV files\n",
    "csv_files = find_csv_files(INPUT_CSV_DIRECTORY)\n",
    "print(f\"Starting to process {len(csv_files)} CSV files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "processed_files = []\n",
    "failed_files = []\n",
    "all_dataframes = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    # pass the HEADER_MAPPING from cell 4 to the processing function\n",
    "    cleaned_df = process_single_csv(file_path, HEADER_MAPPING, add_source_info=True)\n",
    "\n",
    "    # check if processing was successful (function did not return None)\n",
    "    if cleaned_df is not None:\n",
    "        processed_files.append(file_path)\n",
    "        # append the DataFrame only if processing was successful and it's not empty\n",
    "        if not cleaned_df.empty:\n",
    "             all_dataframes.append(cleaned_df)\n",
    "             print(f\"  Success: {len(cleaned_df)} rows extracted\")\n",
    "        else:\n",
    "             # file processed successfully but resulted in an empty DataFrame after cleaning\n",
    "             print(f\"  Success: No rows extracted after cleaning\")\n",
    "\n",
    "    else:\n",
    "        # file processing failed (due to empty file or unexpected error)\n",
    "        failed_files.append(file_path)\n",
    "        print(f\"  Failed to process\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Processing Summary:\")\n",
    "print(f\"  Total files: {len(csv_files)}\")\n",
    "print(f\"  Successfully processed: {len(processed_files)}\")\n",
    "print(f\"  Failed: {len(failed_files)}\")\n",
    "print(f\"  Total rows extracted: {sum(len(df) for df in all_dataframes)}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\nFailed files:\")\n",
    "    for failed_file in failed_files:\n",
    "        print(f\"  - {os.path.basename(failed_file)}\")\n",
    "    \n",
    "    # a process where in it states what file failed and why\n",
    "    print(\"\\nheaders:\")\n",
    "    for failed_file in failed_files:\n",
    "        try:\n",
    "            df = pd.read_csv(failed_file, nrows=0)\n",
    "            print(f\"  - {os.path.basename(failed_file)} headers: {list(df.columns)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - {os.path.basename(failed_file)} error: {e}\")\n",
    "\n",
    "print(\"\\nIndividual processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062793d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 57 cleaned CSV files...\n",
      "----------------------------------------\n",
      "Saved: AUTOMAT_SYLLABUS_2ndTerm_2024_ver3.0_cleaned.csv (10 rows)\n",
      "Saved: CLDCOMP_Syllabus 2023-2024_cleaned.csv (11 rows)\n",
      "Saved: CLDSRV2_Syllabus 2023_2024_cleaned.csv (5 rows)\n",
      "Saved: CLDSRV2_Syllabus_2024_cleaned.csv (10 rows)\n",
      "Saved: COMPORG_SYLLABUS_AY2024_2025_cleaned.csv (11 rows)\n",
      "Saved: COMSEC2_Syllabus_2024_cleaned.csv (13 rows)\n",
      "Saved: COMSEC3_Syllabus_2024 - 2025_cleaned.csv (9 rows)\n",
      "Saved: COMSECT_Syllabus_2024_cleaned.csv (13 rows)\n",
      "Saved: Course Syllabus PHYSICS1 Natural Physics 1 for IT_cleaned.csv (10 rows)\n",
      "Saved: Course Syllabus PHYSICS2 Natural Physics 2 for IT_cleaned.csv (10 rows)\n",
      "Saved: CRISKMA Syllabus AY 2024 - 2025_cleaned.csv (7 rows)\n",
      "Saved: CSPROJ2 Course Syllabus AY2024-2025 (KRC)v.03_cleaned.csv (1 rows)\n",
      "Saved: DASTRUC_Syllabus T1 AY 2024-2025 Revise version_cleaned.csv (11 rows)\n",
      "Saved: DATAMA1_SYLLABUS_2024_1st_term_Version_cleaned.csv (11 rows)\n",
      "Saved: DATAMA1_SYLLABUS_Ver3.0_2023_cleaned.csv (11 rows)\n",
      "Saved: DATAMA2_SYLLABUS_1st_Term_2024_version_cleaned.csv (12 rows)\n",
      "Saved: DATAMA2_SYLLABUS_2nd_Term_2024_version3.0_cleaned.csv (12 rows)\n",
      "Saved: DESALGO_Syllabus_2024_cleaned.csv (7 rows)\n",
      "Saved: ENTJAVA (Using C# .NET) Course Syllabus 2023-2024_cleaned.csv (11 rows)\n",
      "Saved: ICTSRV1_Syllabus_2024_cleaned.csv (15 rows)\n",
      "Saved: INFOSEC_Syllabus_2023_cleaned.csv (13 rows)\n",
      "Saved: INFOSEC_Syllabus_T1_AY_2024_2025_cleaned.csv (13 rows)\n",
      "Saved: INPROLA Syllabus 2ndTerm_2024ver3.0_cleaned.csv (8 rows)\n",
      "Saved: INPROLA Syllabus Revision T1 A.Y. 2023 Revise Oct 2023_cleaned.csv (9 rows)\n",
      "Saved: INPROLA Syllabus T1 A.Y. 2024-2025 Revise version_cleaned.csv (18 rows)\n",
      "Saved: INTCOMC_Syllabus 2024-2025_cleaned.csv (13 rows)\n",
      "Saved: INTSDEV_Syllabus_2023-2024_cleaned.csv (7 rows)\n",
      "Saved: ITCONCE_SYLLABUS_AY2023-2024 - Revise Oct 2023_cleaned.csv (13 rows)\n",
      "Saved: MCSPROJ Course Syllabus AY2024-2025 for IT_cleaned.csv (3 rows)\n",
      "Saved: MNSYSIT Course Syllabus AY 2024-2025_cleaned.csv (4 rows)\n",
      "Saved: MNSYSIT Salesforce_AY 2023-2024 v2_cleaned.csv (4 rows)\n",
      "Saved: MNSYSIT Salesforce_T1 AY 2024-2025 for upload_cleaned.csv (2 rows)\n",
      "Saved: MNTSDEV-SNTSDEV-INTSDEV Course Syllabus 2023 - 2024_cleaned.csv (7 rows)\n",
      "Saved: MNTSDEV-SNTSDEV-INTSDEV Course Syllabus AY 2024 - 2025 v2_cleaned.csv (6 rows)\n",
      "Saved: MOBAPPL  Syllabus T2 A.Y. 2024-2025 Revise version_cleaned.csv (14 rows)\n",
      "Saved: MOBPROG Course Syllabus 1T 2022 - Revise Oct 2023_cleaned.csv (16 rows)\n",
      "Saved: MOBPROG Course Syllabus 1T 2024-2025 Revise version_cleaned.csv (16 rows)\n",
      "Saved: MODESIM_Syllabus_2024_cleaned.csv (11 rows)\n",
      "Saved: NETDESM_2024_cleaned.csv (13 rows)\n",
      "Saved: OPESYST_SYLLABUS_AY2024-2025_cleaned.csv (19 rows)\n",
      "Saved: PROGCON Syllabus Revision  T1 A.Y. 2023-2024 Revise Oct 2023_cleaned.csv (15 rows)\n",
      "Saved: PROGCON_SYLLABUS_2024_1stTerm_version_cleaned.csv (9 rows)\n",
      "Saved: PROGCON_SYLLABUS_2ndTerm_2024_3.0_cleaned.csv (9 rows)\n",
      "Saved: PROJMAN AY 2023_2024 Syllabus_cleaned.csv (10 rows)\n",
      "Saved: PROJMAN _Syllabus_T1 AY 2024-2025_cleaned.csv (14 rows)\n",
      "Saved: QUALITY_SYLLABUS_2023 for CS_cleaned.csv (12 rows)\n",
      "Saved: QUALITY_SYLLABUS_AY_2023_2024 for IT_cleaned.csv (12 rows)\n",
      "Saved: SCSPROJ - MCSPROJ Course Syllabus AY 2023 - 2024_cleaned.csv (3 rows)\n",
      "Saved: SCSPROJ Course Syllabus AY2024-2025 for CS_cleaned.csv (3 rows)\n",
      "Saved: Softdev Syllabus 2023 - 2024 for CS and IT_cleaned.csv (10 rows)\n",
      "Saved: SOFTDEV_Syllabus_T1_AY_ 2024_2025_for_CS_and _T_cleaned.csv (10 rows)\n",
      "Saved: SSYADD1-MSYADD1_Syllabus_2023_cleaned.csv (6 rows)\n",
      "Saved: SSYADD1-MSYADD1_Syllabus_T1 AY 2024-2025_cleaned.csv (14 rows)\n",
      "Saved: THESIS2 2023 Syllabus  T1 AY 2024 2025_cleaned.csv (10 rows)\n",
      "Saved: USERDES Course Syllabus 1T 2020_cleaned.csv (13 rows)\n",
      "Saved: WEBPROG_Syllabus_2023_2024_cleaned.csv (13 rows)\n",
      "Saved: WEBPSEC_Syllabus_2024_cleaned.csv (13 rows)\n",
      "----------------------------------------\n",
      "Individual file saving completed\n",
      "Saved 57 files to: cleaned_csv\n",
      "\n",
      "First 5 saved files:\n",
      "  1. AUTOMAT_SYLLABUS_2ndTerm_2024_ver3.0_cleaned.csv\n",
      "  2. CLDCOMP_Syllabus 2023-2024_cleaned.csv\n",
      "  3. CLDSRV2_Syllabus 2023_2024_cleaned.csv\n",
      "  4. CLDSRV2_Syllabus_2024_cleaned.csv\n",
      "  5. COMPORG_SYLLABUS_AY2024_2025_cleaned.csv\n",
      "  ... and 52 more files\n",
      "\n",
      "Individual file saving completed\n"
     ]
    }
   ],
   "source": [
    "def save_individual_files(dataframes_list, original_files_list, output_directory):\n",
    "    \"\"\"Save each cleaned DataFrame as an individual CSV file.\"\"\"\n",
    "    saved_files = []\n",
    "    \n",
    "    print(f\"Saving {len(dataframes_list)} cleaned CSV files...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for df, original_file_path in zip(dataframes_list, original_files_list):\n",
    "        try:\n",
    "            # Create output filename\n",
    "            original_name = Path(original_file_path).stem\n",
    "            cleaned_filename = f\"{original_name}_cleaned.csv\"\n",
    "            output_path = Path(output_directory) / cleaned_filename\n",
    "            \n",
    "            # Save the file\n",
    "            df.to_csv(output_path, index=False)\n",
    "            saved_files.append(str(output_path))\n",
    "            \n",
    "            print(f\"Saved: {cleaned_filename} ({len(df)} rows)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving {os.path.basename(original_file_path)}: {str(e)}\")\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "# Save individual cleaned files\n",
    "if all_dataframes:\n",
    "    saved_individual_files = save_individual_files(all_dataframes, processed_files, OUTPUT_DIRECTORY)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Individual file saving completed\")\n",
    "    print(f\"Saved {len(saved_individual_files)} files to: {OUTPUT_DIRECTORY}\")\n",
    "    \n",
    "    # Show first few saved files\n",
    "    print(f\"\\nFirst 5 saved files:\")\n",
    "    for i, saved_file in enumerate(saved_individual_files[:5]):\n",
    "        print(f\"  {i+1}. {os.path.basename(saved_file)}\")\n",
    "    \n",
    "    if len(saved_individual_files) > 5:\n",
    "        print(f\"  ... and {len(saved_individual_files) - 5} more files\")\n",
    "        \n",
    "else:\n",
    "    print(\"No dataframes to save - check previous steps for errors\")\n",
    "\n",
    "print(\"\\nIndividual file saving completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d59606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined dataset from 57 files...\n",
      "Sorted by source file\n",
      "Combined dataset saved to: combined_csv\\combined_cleaned_syllabi_data.csv\n",
      "Total rows in combined dataset: 585\n",
      "Columns: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments', 'Source_File', 'Course_Code']\n",
      "\n",
      "Rows per source file:\n",
      "  Total unique files: 57\n",
      "  Average rows per file: 10.3\n",
      "  Min rows per file: 1\n",
      "  Max rows per file: 19\n",
      "\n",
      "Top 10 files by row count:\n",
      "  1. OPESYST_SYLLABUS_AY2024-2025.csv: 19 rows\n",
      "  2. INPROLA Syllabus T1 A.Y. 2024-2025 Revise version.csv: 18 rows\n",
      "  3. MOBPROG Course Syllabus 1T 2024-2025 Revise version.csv: 16 rows\n",
      "  4. MOBPROG Course Syllabus 1T 2022 - Revise Oct 2023.csv: 16 rows\n",
      "  5. ICTSRV1_Syllabus_2024.csv: 15 rows\n",
      "  6. PROGCON Syllabus Revision  T1 A.Y. 2023-2024 Revise Oct 2023.csv: 15 rows\n",
      "  7. SSYADD1-MSYADD1_Syllabus_T1 AY 2024-2025.csv: 14 rows\n",
      "  8. PROJMAN _Syllabus_T1 AY 2024-2025.csv: 14 rows\n",
      "  9. MOBAPPL  Syllabus T2 A.Y. 2024-2025 Revise version.csv: 14 rows\n",
      "  10. INTCOMC_Syllabus 2024-2025.csv: 13 rows\n",
      "\n",
      "Data quality summary:\n",
      "  Learning Outcomes: 576/585 (98.5%) non-empty\n",
      "  Deliverables: 472/585 (80.7%) non-empty\n",
      "  Assessments: 562/585 (96.1%) non-empty\n",
      "\n",
      "Combined dataset creation completed\n",
      "File location: combined_csv\\combined_cleaned_syllabi_data.csv\n",
      "\n",
      "Combined dataset ready\n"
     ]
    }
   ],
   "source": [
    "def create_combined_dataset(dataframes_list, output_directory, filename=\"combined_cleaned_syllabi_data.csv\"):\n",
    "    \"\"\"Combine all cleaned DataFrames into a single CSV file.\"\"\"\n",
    "    \n",
    "    if not dataframes_list:\n",
    "        print(\"No dataframes to combine\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Creating combined dataset from {len(dataframes_list)} files...\")\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "    \n",
    "    # Sort by source file for better organization\n",
    "    if 'Source_File' in combined_df.columns:\n",
    "        combined_df = combined_df.sort_values('Source_File').reset_index(drop=True)\n",
    "        print(\"Sorted by source file\")\n",
    "    \n",
    "    # Create output path\n",
    "    output_path = Path(output_directory) / filename\n",
    "    \n",
    "    # Save combined file\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Combined dataset saved to: {output_path}\")\n",
    "    print(f\"Total rows in combined dataset: {len(combined_df)}\")\n",
    "    print(f\"Columns: {list(combined_df.columns)}\")\n",
    "    \n",
    "    # Show summary by source file\n",
    "    if 'Source_File' in combined_df.columns:\n",
    "        file_counts = combined_df['Source_File'].value_counts()\n",
    "        print(f\"\\nRows per source file:\")\n",
    "        print(f\"  Total unique files: {len(file_counts)}\")\n",
    "        print(f\"  Average rows per file: {file_counts.mean():.1f}\")\n",
    "        print(f\"  Min rows per file: {file_counts.min()}\")\n",
    "        print(f\"  Max rows per file: {file_counts.max()}\")\n",
    "        \n",
    "        print(f\"\\nTop 10 files by row count:\")\n",
    "        for i, (filename, count) in enumerate(file_counts.head(10).items()):\n",
    "            print(f\"  {i+1}. {filename}: {count} rows\")\n",
    "    \n",
    "    # Show data quality summary\n",
    "    print(f\"\\nData quality summary:\")\n",
    "    for col in ['Learning Outcomes', 'Deliverables', 'Assessments']:\n",
    "        if col in combined_df.columns:\n",
    "            non_empty = combined_df[col].str.len() > 0\n",
    "            non_empty_count = non_empty.sum()\n",
    "            percentage = (non_empty_count / len(combined_df)) * 100\n",
    "            print(f\"  {col}: {non_empty_count}/{len(combined_df)} ({percentage:.1f}%) non-empty\")\n",
    "    \n",
    "    return str(output_path)\n",
    "\n",
    "# Create combined dataset\n",
    "if all_dataframes:\n",
    "    combined_file_path = create_combined_dataset(\n",
    "        all_dataframes, \n",
    "        COMBINED_OUTPUT_DIR, \n",
    "        \"combined_cleaned_syllabi_data.csv\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCombined dataset creation completed\")\n",
    "    print(f\"File location: {combined_file_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No dataframes available for combining\")\n",
    "\n",
    "print(\"\\nCombined dataset ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ae19fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "INPUT:\n",
      "  Source directory: csv_outputs\n",
      "  Total CSV files found: 57\n",
      "\n",
      "PROCESSING RESULTS:\n",
      "  Successfully processed: 57\n",
      "  Failed to process: 0\n",
      "  Success rate: 100.0%\n",
      "  Total rows extracted: 585\n",
      "  Average rows per file: 10.3\n",
      "\n",
      "OUTPUT:\n",
      "  Individual cleaned files: cleaned_csv\n",
      "    Number of files: 57\n",
      "  Combined dataset: combined_csv\n",
      "    Combined file rows: 585\n",
      "    Combined file columns: ['Week', 'Learning Outcomes', 'Deliverables', 'Assessments', 'Source_File', 'Course_Code']\n",
      "\n",
      "HEADER MAPPING USED:\n",
      "  Week:\n",
      "    - Week\n",
      "    - Week No\n",
      "    - Week #\n",
      "    - ... and 2 more variations\n",
      "  Learning Outcomes:\n",
      "    - Learning Outcomes\n",
      "    - Learning Outcome\n",
      "    - Learning\\nOutcomes\n",
      "    - ... and 5 more variations\n",
      "  Deliverables:\n",
      "    - Deliverables Outcomes\n",
      "    - Deliverables/Outcomes\n",
      "    - Deliverables\n",
      "    - ... and 7 more variations\n",
      "  Assessments:\n",
      "    - Assessments\n",
      "    - Assessment\n",
      "    - Assessment Task\n",
      "    - ... and 1 more variations\n",
      "============================================================\n",
      "PROCESS COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "VALIDATION:\n",
      "------------------------------\n",
      "Individual cleaned files: 57 found\n",
      "Combined file: EXISTS\n",
      "  Shape: (585, 6)\n",
      "  All required columns present: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Data completeness:\n",
      "    Learning Outcomes: 585/585 (100.0%) non-empty\n",
      "    Deliverables: 585/585 (100.0%) non-empty\n",
      "    Assessments: 585/585 (100.0%) non-empty\n",
      "------------------------------\n",
      "Validation completed\n",
      "\n",
      "============================================================\n",
      "ALL STEPS COMPLETED\n",
      "============================================================\n",
      "\n",
      "Your cleaned data is ready:\n",
      "1. Individual files: cleaned_csv\n",
      "2. Combined file: combined_csv/combined_cleaned_syllabi_data.csv\n"
     ]
    }
   ],
   "source": [
    "def generate_final_summary():\n",
    "    \"\"\"Generate a comprehensive summary of the entire process.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"FINAL PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Input summary\n",
    "    print(f\"\\nINPUT:\")\n",
    "    print(f\"  Source directory: {INPUT_CSV_DIRECTORY}\")\n",
    "    csv_files = find_csv_files(INPUT_CSV_DIRECTORY)\n",
    "    print(f\"  Total CSV files found: {len(csv_files)}\")\n",
    "    \n",
    "    # Processing summary\n",
    "    print(f\"\\nPROCESSING RESULTS:\")\n",
    "    print(f\"  Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"  Failed to process: {len(failed_files)}\")\n",
    "    print(f\"  Success rate: {(len(processed_files)/len(csv_files)*100):.1f}%\")\n",
    "    \n",
    "    if all_dataframes:\n",
    "        total_rows = sum(len(df) for df in all_dataframes)\n",
    "        print(f\"  Total rows extracted: {total_rows}\")\n",
    "        print(f\"  Average rows per file: {total_rows/len(all_dataframes):.1f}\")\n",
    "    \n",
    "    # Output summary\n",
    "    print(f\"\\nOUTPUT:\")\n",
    "    print(f\"  Individual cleaned files: {OUTPUT_DIRECTORY}\")\n",
    "    if all_dataframes:\n",
    "        print(f\"    Number of files: {len(all_dataframes)}\")\n",
    "    \n",
    "    print(f\"  Combined dataset: {COMBINED_OUTPUT_DIR}\")\n",
    "    \n",
    "    # Check if combined file exists and get its info\n",
    "    combined_file = Path(COMBINED_OUTPUT_DIR) / \"combined_cleaned_syllabi_data.csv\"\n",
    "    if combined_file.exists():\n",
    "        try:\n",
    "            combined_df = pd.read_csv(combined_file)\n",
    "            print(f\"    Combined file rows: {len(combined_df)}\")\n",
    "            print(f\"    Combined file columns: {list(combined_df.columns)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Error reading combined file: {e}\")\n",
    "    \n",
    "    # Failed files details\n",
    "    if failed_files:\n",
    "        print(f\"\\nFAILED FILES:\")\n",
    "        for i, failed_file in enumerate(failed_files, 1):\n",
    "            print(f\"  {i}. {os.path.basename(failed_file)}\")\n",
    "    \n",
    "    # Header mapping summary\n",
    "    print(f\"\\nHEADER MAPPING USED:\")\n",
    "    for canonical, variations in HEADER_MAPPING.items():\n",
    "        print(f\"  {canonical}:\")\n",
    "        for variation in variations[:3]:  # Show first 3 variations\n",
    "            print(f\"    - {variation}\")\n",
    "        if len(variations) > 3:\n",
    "            print(f\"    - ... and {len(variations)-3} more variations\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"PROCESS COMPLETED SUCCESSFULLY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "def validate_output():\n",
    "    \"\"\"Validate the output files.\"\"\"\n",
    "    \n",
    "    print(\"\\nVALIDATION:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Check individual files\n",
    "    individual_files = glob.glob(os.path.join(OUTPUT_DIRECTORY, \"*_cleaned.csv\"))\n",
    "    print(f\"Individual cleaned files: {len(individual_files)} found\")\n",
    "    \n",
    "    # Check combined file\n",
    "    combined_file = Path(COMBINED_OUTPUT_DIR) / \"combined_cleaned_syllabi_data.csv\"\n",
    "    if combined_file.exists():\n",
    "        print(f\"Combined file: EXISTS\")\n",
    "        \n",
    "        # Quick validation of combined file\n",
    "        try:\n",
    "            df_combined = pd.read_csv(combined_file)\n",
    "            print(f\"  Shape: {df_combined.shape}\")\n",
    "            \n",
    "            # Check required columns\n",
    "            required_cols = ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
    "            missing_cols = [col for col in required_cols if col not in df_combined.columns]\n",
    "            \n",
    "            if missing_cols:\n",
    "                print(f\"  Warning: Missing columns: {missing_cols}\")\n",
    "            else:\n",
    "                print(f\"  All required columns present: {required_cols}\")\n",
    "            \n",
    "            # Check data completeness\n",
    "            print(f\"  Data completeness:\")\n",
    "            for col in required_cols:\n",
    "                if col in df_combined.columns:\n",
    "                    non_empty = (df_combined[col].astype(str).str.len() > 0) & (df_combined[col] != 'nan')\n",
    "                    count = non_empty.sum()\n",
    "                    percent = (count / len(df_combined)) * 100\n",
    "                    print(f\"    {col}: {count}/{len(df_combined)} ({percent:.1f}%) non-empty\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error validating combined file: {e}\")\n",
    "    else:\n",
    "        print(f\"Combined file: NOT FOUND\")\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(\"Validation completed\")\n",
    "\n",
    "# Generate final summary\n",
    "generate_final_summary()\n",
    "\n",
    "# Validate output\n",
    "validate_output()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL STEPS COMPLETED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nYour cleaned data is ready:\")\n",
    "print(f\"1. Individual files: {OUTPUT_DIRECTORY}\")\n",
    "print(f\"2. Combined file: {COMBINED_OUTPUT_DIR}/combined_cleaned_syllabi_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
