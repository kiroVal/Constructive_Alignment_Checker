{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "610b9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of textract: .* suffix can only be used with `==` or `!=` operators\n",
      "    extract-msg (<=0.29.*)\n",
      "                 ~~~~~~~^\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7f53a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: glob2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of textract: .* suffix can only be used with `==` or `!=` operators\n",
      "    extract-msg (<=0.29.*)\n",
      "                 ~~~~~~~^\n"
     ]
    }
   ],
   "source": [
    "%pip install glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cb40c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages are imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "print(\"packages are imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35c94e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory: csv_outputs\n",
      "Output directory: cleaned_csv\n",
      "Combined output directory: combined_csv\n",
      "Configuration completed successfully\n"
     ]
    }
   ],
   "source": [
    "INPUT_CSV_DIRECTORY = \"csv_outputs\"          \n",
    "OUTPUT_DIRECTORY = \"cleaned_csv\"             \n",
    "COMBINED_OUTPUT_DIR = \"combined_csv\"         \n",
    "\n",
    "# Define canonical headers and their possible variations (based on your DOCX extraction)\n",
    "HEADER_MAPPING = {\n",
    "    \"Learning Outcomes\": [\n",
    "        \"Learning Outcomes\", \"Learning Outcome\", \"Learning\\\\nOutcomes\",\n",
    "        \"Learning Outcomes (LO) / Learner and Learning Outcomes (LLO)\",\n",
    "        \"Learning Outcomes\\\\n(At the end of the session, students are expected to:)\",\n",
    "        \"Learning Outcomes\\\\n(At the end of the session, students are expected to :)\",\n",
    "        \"Learning\\\\nOutcomes\", \"Learning \\\\nOutcomes\"\n",
    "    ],\n",
    "    \"Deliverables\": [\n",
    "        \"Deliverables Outcomes\", \"Deliverables/Outcomes\", \"Deliverables\", \n",
    "        \"Deliverables/\\\\nOutcomes\", \"Deliverables\\\\n/ Outcomes\", \"Deliverables/ Outcomes\",\n",
    "        \"Deliverables/\\\\xa0 Outcomes\", \"Deliverables/\\\\xa0\\\\nOutcomes\", \n",
    "        \"Deliverable / Outcomes\", \"Deliverables\\\\n/ Outcomes/Rubrics\"\n",
    "    ],\n",
    "    \"Assessments\": [\n",
    "        \"Assessments\", \"Assessment\", \"Assessment Task\", \"Assessment\\\\n/ Output\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(COMBINED_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Input directory: {INPUT_CSV_DIRECTORY}\")\n",
    "print(f\"Output directory: {OUTPUT_DIRECTORY}\")\n",
    "print(f\"Combined output directory: {COMBINED_OUTPUT_DIR}\")\n",
    "print(\"Configuration completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "400707fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "def normalize_header(text):\n",
    "    \"\"\"\n",
    "    Normalize header text: lowercase, remove spaces, slashes, punctuation.\n",
    "    Same logic as your DOCX extraction script.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-z0-9]', '', text.lower())\n",
    "\n",
    "def find_csv_files(directory):\n",
    "    \"\"\"Find all CSV files in the specified directory.\"\"\"\n",
    "    csv_pattern = os.path.join(directory, \"*.csv\")\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    return csv_files\n",
    "\n",
    "def match_headers_to_canonical(df_headers, header_mapping):\n",
    "    \"\"\"\n",
    "    Match DataFrame headers to canonical headers using substring matching.\n",
    "    Returns matched canonical headers, column indices, and final header names.\n",
    "    \"\"\"\n",
    "    matched_canonical_headers = []\n",
    "    col_indices = []\n",
    "    final_headers = []\n",
    "    \n",
    "    # Normalize input headers\n",
    "    normalized_df_headers = [normalize_header(h) for h in df_headers]\n",
    "    \n",
    "    for canonical_header, possible_variations in header_mapping.items():\n",
    "        found_variation_index = -1\n",
    "        \n",
    "        # Check if any variation matches as substring\n",
    "        for variation in possible_variations:\n",
    "            normalized_variation = normalize_header(variation)\n",
    "            \n",
    "            for j, normalized_table_header in enumerate(normalized_df_headers):\n",
    "                if normalized_variation in normalized_table_header or normalized_table_header in normalized_variation:\n",
    "                    found_variation_index = j\n",
    "                    break\n",
    "                    \n",
    "            if found_variation_index != -1:\n",
    "                break\n",
    "        \n",
    "        if found_variation_index != -1:\n",
    "            col_indices.append(found_variation_index)\n",
    "            final_headers.append(canonical_header)\n",
    "            matched_canonical_headers.append(canonical_header)\n",
    "            \n",
    "    return matched_canonical_headers, col_indices, final_headers\n",
    "\n",
    "def clean_text_data(df):\n",
    "    \"\"\"Clean text data removing common DOCX extraction artifacts.\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    for col in df_clean.columns:\n",
    "        if df_clean[col].dtype == 'object':\n",
    "            # Strip whitespace\n",
    "            df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "            \n",
    "            # Replace 'nan' string with empty string\n",
    "            df_clean[col] = df_clean[col].replace(['nan', 'NaN'], '')\n",
    "            \n",
    "            # Clean up common formatting issues from DOCX extraction\n",
    "            df_clean[col] = df_clean[col].str.replace('\\\\n', ' ', regex=False)\n",
    "            df_clean[col] = df_clean[col].str.replace('\\\\xa0', ' ', regex=False)\n",
    "            df_clean[col] = df_clean[col].str.replace('  +', ' ', regex=True)  # Multiple spaces to single\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "print(\"functions defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b0fc1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting header analysis...\n",
      "Found 58 CSV files to analyze\n",
      "Analyzing headers...\n",
      "\n",
      "Total files found: 58\n",
      "\n",
      "Sample headers from first 5 files:\n",
      "--------------------------------------------------\n",
      "AUTOMAT_SYLLABUS_2ndTerm_2024_ver3.0.csv:\n",
      "  Headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "\n",
      "CLDCOMP_Syllabus 2023-2024.csv:\n",
      "  Headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "\n",
      "CLDSRV2_Syllabus 2023_2024.csv:\n",
      "  Headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "\n",
      "CLDSRV2_Syllabus_2024.csv:\n",
      "  Headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "\n",
      "COMPORG_SYLLABUS_AY2024_2025.csv:\n",
      "  Headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "\n",
      "Checking for target headers in all files...\n",
      "\n",
      "Target header distribution:\n",
      "  Learning Outcomes: found in 57/58 files\n",
      "  Deliverables: found in 52/58 files\n",
      "  Assessments: found in 57/58 files\n",
      "\n",
      "Header analysis completed\n"
     ]
    }
   ],
   "source": [
    "def analyze_csv_headers(input_directory):\n",
    "    \"\"\"Analyze headers across all CSV files.\"\"\"\n",
    "    csv_files = find_csv_files(input_directory)\n",
    "    header_analysis = {}\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files to analyze\")\n",
    "    print(\"Analyzing headers...\")\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, nrows=0)  # Read only headers\n",
    "            filename = os.path.basename(file_path)\n",
    "            header_analysis[filename] = list(df.columns)\n",
    "        except Exception as e:\n",
    "            filename = os.path.basename(file_path)\n",
    "            header_analysis[filename] = f\"Error: {str(e)}\"\n",
    "    \n",
    "    return header_analysis\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Starting header analysis...\")\n",
    "headers = analyze_csv_headers(INPUT_CSV_DIRECTORY)\n",
    "\n",
    "# Show sample of headers from first 5 files\n",
    "print(f\"\\nTotal files found: {len(headers)}\")\n",
    "print(\"\\nSample headers from first 5 files:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "count = 0\n",
    "for filename, file_headers in headers.items():\n",
    "    if count < 5:\n",
    "        if isinstance(file_headers, list):\n",
    "            print(f\"{filename}:\")\n",
    "            print(f\"  Headers: {file_headers}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"{filename}: {file_headers}\")\n",
    "            print()\n",
    "        count += 1\n",
    "\n",
    "# Check which files have the target headers\n",
    "print(\"Checking for target headers in all files...\")\n",
    "target_header_count = {\"Learning Outcomes\": 0, \"Deliverables\": 0, \"Assessments\": 0}\n",
    "\n",
    "for filename, file_headers in headers.items():\n",
    "    if isinstance(file_headers, list):\n",
    "        normalized_headers = [normalize_header(h) for h in file_headers]\n",
    "        \n",
    "        # Check each canonical header\n",
    "        for canonical_header, variations in HEADER_MAPPING.items():\n",
    "            found = False\n",
    "            for variation in variations:\n",
    "                normalized_variation = normalize_header(variation)\n",
    "                for norm_header in normalized_headers:\n",
    "                    if normalized_variation in norm_header or norm_header in normalized_variation:\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "            if found:\n",
    "                target_header_count[canonical_header] += 1\n",
    "\n",
    "print(\"\\nTarget header distribution:\")\n",
    "for header, count in target_header_count.items():\n",
    "    print(f\"  {header}: found in {count}/{len(headers)} files\")\n",
    "\n",
    "print(\"\\nHeader analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ff16c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 58 CSV files...\n",
      "============================================================\n",
      "Processing: AUTOMAT_SYLLABUS_2ndTerm_2024_ver3.0.csv\n",
      "  Original shape: (10, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 5)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "\n",
      "Processing: CLDCOMP_Syllabus 2023-2024.csv\n",
      "  Original shape: (11, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 5)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "\n",
      "Processing: CLDSRV2_Syllabus 2023_2024.csv\n",
      "  Original shape: (5, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (5, 5)\n",
      "  Successfully processed\n",
      "  Success: 5 rows extracted\n",
      "\n",
      "Processing: CLDSRV2_Syllabus_2024.csv\n",
      "  Original shape: (10, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 5)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "\n",
      "Processing: COMPORG_SYLLABUS_AY2024_2025.csv\n",
      "  Original shape: (11, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 5)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "\n",
      "Processing: COMSEC2_Syllabus_2024.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: COMSEC3_Syllabus_2024 - 2025.csv\n",
      "  Original shape: (9, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (9, 5)\n",
      "  Successfully processed\n",
      "  Success: 9 rows extracted\n",
      "\n",
      "Processing: COMSECT_Syllabus_2024.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: Course Syllabus PHYSICS1 Natural Physics 1 for IT.csv\n",
      "  Original shape: (10, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 5)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "\n",
      "Processing: Course Syllabus PHYSICS2 Natural Physics 2 for IT.csv\n",
      "  Original shape: (10, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 5)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "\n",
      "Processing: course_outline.csv\n",
      "  Original shape: (12, 7)\n",
      "  Original headers: ['0', '1', '2', '3', '4', '5', '6']\n",
      "  Warning: Only found 1 relevant headers: ['Deliverables']\n",
      "  Failed to process\n",
      "\n",
      "Processing: CRISKMA Syllabus AY 2024 - 2025.csv\n",
      "  Original shape: (7, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (7, 5)\n",
      "  Successfully processed\n",
      "  Success: 7 rows extracted\n",
      "\n",
      "Processing: CSPROJ2 Course Syllabus AY2024-2025 (KRC)v.03.csv\n",
      "  Original shape: (1, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (1, 5)\n",
      "  Successfully processed\n",
      "  Success: 1 rows extracted\n",
      "\n",
      "Processing: DASTRUC_Syllabus T1 AY 2024-2025 Revise version.csv\n",
      "  Original shape: (11, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 5)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "\n",
      "Processing: DATAMA1_SYLLABUS_2024_1st_term_Version.csv\n",
      "  Original shape: (11, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 5)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "\n",
      "Processing: DATAMA1_SYLLABUS_Ver3.0_2023.csv\n",
      "  Original shape: (11, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 5)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "\n",
      "Processing: DATAMA2_SYLLABUS_1st_Term_2024_version.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (12, 5)\n",
      "  Successfully processed\n",
      "  Success: 12 rows extracted\n",
      "\n",
      "Processing: DATAMA2_SYLLABUS_2nd_Term_2024_version3.0.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (12, 5)\n",
      "  Successfully processed\n",
      "  Success: 12 rows extracted\n",
      "\n",
      "Processing: DESALGO_Syllabus_2024.csv\n",
      "  Original shape: (7, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (7, 5)\n",
      "  Successfully processed\n",
      "  Success: 7 rows extracted\n",
      "\n",
      "Processing: ENTJAVA (Using C# .NET) Course Syllabus 2023-2024.csv\n",
      "  Original shape: (11, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 5)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "\n",
      "Processing: ICTSRV1_Syllabus_2024.csv\n",
      "  Original shape: (15, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (15, 5)\n",
      "  Successfully processed\n",
      "  Success: 15 rows extracted\n",
      "\n",
      "Processing: INFOSEC_Syllabus_2023.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: INFOSEC_Syllabus_T1_AY_2024_2025.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: INPROLA Syllabus 2ndTerm_2024ver3.0.csv\n",
      "  Original shape: (8, 2)\n",
      "  Original headers: ['Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Assessments']\n",
      "  Final shape: (8, 5)\n",
      "  Successfully processed\n",
      "  Success: 8 rows extracted\n",
      "\n",
      "Processing: INPROLA Syllabus Revision T1 A.Y. 2023 Revise Oct 2023.csv\n",
      "  Original shape: (9, 2)\n",
      "  Original headers: ['Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Assessments']\n",
      "  Final shape: (9, 5)\n",
      "  Successfully processed\n",
      "  Success: 9 rows extracted\n",
      "\n",
      "Processing: INPROLA Syllabus T1 A.Y. 2024-2025 Revise version.csv\n",
      "  Original shape: (18, 2)\n",
      "  Original headers: ['Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Assessments']\n",
      "  Final shape: (18, 5)\n",
      "  Successfully processed\n",
      "  Success: 18 rows extracted\n",
      "\n",
      "Processing: INTCOMC_Syllabus 2024-2025.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: INTSDEV_Syllabus_2023-2024.csv\n",
      "  Original shape: (7, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (7, 5)\n",
      "  Successfully processed\n",
      "  Success: 7 rows extracted\n",
      "\n",
      "Processing: ITCONCE_SYLLABUS_AY2023-2024 - Revise Oct 2023.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: MCSPROJ Course Syllabus AY2024-2025 for IT.csv\n",
      "  Original shape: (3, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (3, 5)\n",
      "  Successfully processed\n",
      "  Success: 3 rows extracted\n",
      "\n",
      "Processing: MNSYSIT Course Syllabus AY 2024-2025.csv\n",
      "  Original shape: (4, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (4, 5)\n",
      "  Successfully processed\n",
      "  Success: 4 rows extracted\n",
      "\n",
      "Processing: MNSYSIT Salesforce_AY 2023-2024 v2.csv\n",
      "  Original shape: (4, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (4, 5)\n",
      "  Successfully processed\n",
      "  Success: 4 rows extracted\n",
      "\n",
      "Processing: MNSYSIT Salesforce_T1 AY 2024-2025 for upload.csv\n",
      "  Original shape: (2, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (2, 5)\n",
      "  Successfully processed\n",
      "  Success: 2 rows extracted\n",
      "\n",
      "Processing: MNTSDEV-SNTSDEV-INTSDEV Course Syllabus 2023 - 2024.csv\n",
      "  Original shape: (7, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (7, 5)\n",
      "  Successfully processed\n",
      "  Success: 7 rows extracted\n",
      "\n",
      "Processing: MNTSDEV-SNTSDEV-INTSDEV Course Syllabus AY 2024 - 2025 v2.csv\n",
      "  Original shape: (6, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (6, 5)\n",
      "  Successfully processed\n",
      "  Success: 6 rows extracted\n",
      "\n",
      "Processing: MOBAPPL  Syllabus T2 A.Y. 2024-2025 Revise version.csv\n",
      "  Original shape: (14, 2)\n",
      "  Original headers: ['Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Assessments']\n",
      "  Final shape: (14, 5)\n",
      "  Successfully processed\n",
      "  Success: 14 rows extracted\n",
      "\n",
      "Processing: MOBPROG Course Syllabus 1T 2022 - Revise Oct 2023.csv\n",
      "  Original shape: (16, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (16, 5)\n",
      "  Successfully processed\n",
      "  Success: 16 rows extracted\n",
      "\n",
      "Processing: MOBPROG Course Syllabus 1T 2024-2025 Revise version.csv\n",
      "  Original shape: (16, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (16, 5)\n",
      "  Successfully processed\n",
      "  Success: 16 rows extracted\n",
      "\n",
      "Processing: MODESIM_Syllabus_2024.csv\n",
      "  Original shape: (11, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (11, 5)\n",
      "  Successfully processed\n",
      "  Success: 11 rows extracted\n",
      "\n",
      "Processing: NETDESM_2024.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: OPESYST_SYLLABUS_AY2024-2025.csv\n",
      "  Original shape: (19, 2)\n",
      "  Original headers: ['Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Assessments']\n",
      "  Final shape: (18, 5)\n",
      "  Successfully processed\n",
      "  Success: 18 rows extracted\n",
      "\n",
      "Processing: PROGCON Syllabus Revision  T1 A.Y. 2023-2024 Revise Oct 2023.csv\n",
      "  Original shape: (15, 2)\n",
      "  Original headers: ['Learning Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Assessments']\n",
      "  Final shape: (15, 5)\n",
      "  Successfully processed\n",
      "  Success: 15 rows extracted\n",
      "\n",
      "Processing: PROGCON_SYLLABUS_2024_1stTerm_version.csv\n",
      "  Original shape: (9, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (9, 5)\n",
      "  Successfully processed\n",
      "  Success: 9 rows extracted\n",
      "\n",
      "Processing: PROGCON_SYLLABUS_2ndTerm_2024_3.0.csv\n",
      "  Original shape: (9, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (9, 5)\n",
      "  Successfully processed\n",
      "  Success: 9 rows extracted\n",
      "\n",
      "Processing: PROJMAN AY 2023_2024 Syllabus.csv\n",
      "  Original shape: (10, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 5)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "\n",
      "Processing: PROJMAN _Syllabus_T1 AY 2024-2025.csv\n",
      "  Original shape: (14, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (14, 5)\n",
      "  Successfully processed\n",
      "  Success: 14 rows extracted\n",
      "\n",
      "Processing: QUALITY_SYLLABUS_2023 for CS.csv\n",
      "  Original shape: (12, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (12, 5)\n",
      "  Successfully processed\n",
      "  Success: 12 rows extracted\n",
      "\n",
      "Processing: QUALITY_SYLLABUS_AY_2023_2024 for IT.csv\n",
      "  Original shape: (12, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (12, 5)\n",
      "  Successfully processed\n",
      "  Success: 12 rows extracted\n",
      "\n",
      "Processing: SCSPROJ - MCSPROJ Course Syllabus AY 2023 - 2024.csv\n",
      "  Original shape: (3, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (3, 5)\n",
      "  Successfully processed\n",
      "  Success: 3 rows extracted\n",
      "\n",
      "Processing: SCSPROJ Course Syllabus AY2024-2025 for CS.csv\n",
      "  Original shape: (3, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (3, 5)\n",
      "  Successfully processed\n",
      "  Success: 3 rows extracted\n",
      "\n",
      "Processing: Softdev Syllabus 2023 - 2024 for CS and IT.csv\n",
      "  Original shape: (10, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 5)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "\n",
      "Processing: SOFTDEV_Syllabus_T1_AY_ 2024_2025_for_CS_and _T.csv\n",
      "  Original shape: (10, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 5)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "\n",
      "Processing: SSYADD1-MSYADD1_Syllabus_2023.csv\n",
      "  Original shape: (6, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (6, 5)\n",
      "  Successfully processed\n",
      "  Success: 6 rows extracted\n",
      "\n",
      "Processing: SSYADD1-MSYADD1_Syllabus_T1 AY 2024-2025.csv\n",
      "  Original shape: (14, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (14, 5)\n",
      "  Successfully processed\n",
      "  Success: 14 rows extracted\n",
      "\n",
      "Processing: THESIS2 2023 Syllabus  T1 AY 2024 2025.csv\n",
      "  Original shape: (10, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (10, 5)\n",
      "  Successfully processed\n",
      "  Success: 10 rows extracted\n",
      "\n",
      "Processing: USERDES Course Syllabus 1T 2020.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: WEBPROG_Syllabus_2023_2024.csv\n",
      "  Original shape: (14, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "Processing: WEBPSEC_Syllabus_2024.csv\n",
      "  Original shape: (13, 3)\n",
      "  Original headers: ['Learning Outcomes', 'Deliverables Outcomes', 'Assessments']\n",
      "  Matched canonical headers: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Final shape: (13, 5)\n",
      "  Successfully processed\n",
      "  Success: 13 rows extracted\n",
      "\n",
      "============================================================\n",
      "Processing Summary:\n",
      "  Total files: 58\n",
      "  Successfully processed: 57\n",
      "  Failed: 1\n",
      "  Total rows extracted: 584\n",
      "\n",
      "Failed files:\n",
      "  - course_outline.csv\n",
      "\n",
      "Individual processing completed\n"
     ]
    }
   ],
   "source": [
    "def process_single_csv(file_path, header_mapping, add_source_info=True):\n",
    "    \"\"\"Process a single CSV file and extract target columns.\"\"\"\n",
    "    try:\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\"Processing: {filename}\")\n",
    "        \n",
    "        # Read CSV with encoding handling\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='latin-1')\n",
    "                print(f\"  Used latin-1 encoding\")\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(file_path, encoding='cp1252')\n",
    "                print(f\"  Used cp1252 encoding\")\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"  Warning: Empty file\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"  Original shape: {df.shape}\")\n",
    "        print(f\"  Original headers: {list(df.columns)}\")\n",
    "        \n",
    "        # Match headers to canonical ones\n",
    "        df_headers = list(df.columns)\n",
    "        matched_canonical_headers, col_indices, final_headers = match_headers_to_canonical(df_headers, header_mapping)\n",
    "        \n",
    "        # Check if we have at least 2 matched headers\n",
    "        if len(matched_canonical_headers) < 2:\n",
    "            print(f\"  Warning: Only found {len(matched_canonical_headers)} relevant headers: {matched_canonical_headers}\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"  Matched canonical headers: {matched_canonical_headers}\")\n",
    "        \n",
    "        # Extract the relevant columns\n",
    "        selected_columns = [df.columns[i] for i in col_indices]\n",
    "        extracted_df = df[selected_columns].copy()\n",
    "        \n",
    "        # Rename columns to canonical names\n",
    "        column_rename_map = dict(zip(selected_columns, final_headers))\n",
    "        extracted_df.rename(columns=column_rename_map, inplace=True)\n",
    "        \n",
    "        # Ensure all three canonical columns exist\n",
    "        all_canonical_headers = [\"Learning Outcomes\", \"Deliverables\", \"Assessments\"]\n",
    "        for canonical_header in all_canonical_headers:\n",
    "            if canonical_header not in extracted_df.columns:\n",
    "                extracted_df[canonical_header] = \"\"\n",
    "                \n",
    "        # Reorder columns\n",
    "        extracted_df = extracted_df[all_canonical_headers]\n",
    "        \n",
    "        # Clean the data\n",
    "        cleaned_df = clean_text_data(extracted_df)\n",
    "        \n",
    "        # Remove completely empty rows\n",
    "        cleaned_df = cleaned_df.dropna(how='all')\n",
    "        \n",
    "        # Remove rows where all target columns are empty\n",
    "        mask = (cleaned_df['Learning Outcomes'].str.len() > 0) | \\\n",
    "               (cleaned_df['Deliverables'].str.len() > 0) | \\\n",
    "               (cleaned_df['Assessments'].str.len() > 0)\n",
    "        cleaned_df = cleaned_df[mask]\n",
    "        \n",
    "        # Add source information if requested\n",
    "        if add_source_info:\n",
    "            cleaned_df['Source_File'] = filename\n",
    "            \n",
    "            # Extract course code from filename\n",
    "            course_match = re.match(r'^([A-Z]+[0-9]*)', filename)\n",
    "            if course_match:\n",
    "                cleaned_df['Course_Code'] = course_match.group(1)\n",
    "            else:\n",
    "                cleaned_df['Course_Code'] = ''\n",
    "        \n",
    "        # Reset index\n",
    "        cleaned_df = cleaned_df.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"  Final shape: {cleaned_df.shape}\")\n",
    "        print(f\"  Successfully processed\")\n",
    "        \n",
    "        return cleaned_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {os.path.basename(file_path)}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Process all CSV files\n",
    "csv_files = find_csv_files(INPUT_CSV_DIRECTORY)\n",
    "print(f\"Starting to process {len(csv_files)} CSV files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "processed_files = []\n",
    "failed_files = []\n",
    "all_dataframes = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    cleaned_df = process_single_csv(file_path, HEADER_MAPPING, add_source_info=True)\n",
    "    \n",
    "    if cleaned_df is not None and not cleaned_df.empty:\n",
    "        processed_files.append(file_path)\n",
    "        all_dataframes.append(cleaned_df)\n",
    "        print(f\"  Success: {len(cleaned_df)} rows extracted\")\n",
    "    else:\n",
    "        failed_files.append(file_path)\n",
    "        print(f\"  Failed to process\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Processing Summary:\")\n",
    "print(f\"  Total files: {len(csv_files)}\")\n",
    "print(f\"  Successfully processed: {len(processed_files)}\")\n",
    "print(f\"  Failed: {len(failed_files)}\")\n",
    "print(f\"  Total rows extracted: {sum(len(df) for df in all_dataframes)}\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\nFailed files:\")\n",
    "    for failed_file in failed_files:\n",
    "        print(f\"  - {os.path.basename(failed_file)}\")\n",
    "\n",
    "print(\"\\nIndividual processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "062793d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 57 cleaned CSV files...\n",
      "----------------------------------------\n",
      "Saved: AUTOMAT_SYLLABUS_2ndTerm_2024_ver3.0_cleaned.csv (10 rows)\n",
      "Saved: CLDCOMP_Syllabus 2023-2024_cleaned.csv (11 rows)\n",
      "Saved: CLDSRV2_Syllabus 2023_2024_cleaned.csv (5 rows)\n",
      "Saved: CLDSRV2_Syllabus_2024_cleaned.csv (10 rows)\n",
      "Saved: COMPORG_SYLLABUS_AY2024_2025_cleaned.csv (11 rows)\n",
      "Saved: COMSEC2_Syllabus_2024_cleaned.csv (13 rows)\n",
      "Saved: COMSEC3_Syllabus_2024 - 2025_cleaned.csv (9 rows)\n",
      "Saved: COMSECT_Syllabus_2024_cleaned.csv (13 rows)\n",
      "Saved: Course Syllabus PHYSICS1 Natural Physics 1 for IT_cleaned.csv (10 rows)\n",
      "Saved: Course Syllabus PHYSICS2 Natural Physics 2 for IT_cleaned.csv (10 rows)\n",
      "Saved: CRISKMA Syllabus AY 2024 - 2025_cleaned.csv (7 rows)\n",
      "Saved: CSPROJ2 Course Syllabus AY2024-2025 (KRC)v.03_cleaned.csv (1 rows)\n",
      "Saved: DASTRUC_Syllabus T1 AY 2024-2025 Revise version_cleaned.csv (11 rows)\n",
      "Saved: DATAMA1_SYLLABUS_2024_1st_term_Version_cleaned.csv (11 rows)\n",
      "Saved: DATAMA1_SYLLABUS_Ver3.0_2023_cleaned.csv (11 rows)\n",
      "Saved: DATAMA2_SYLLABUS_1st_Term_2024_version_cleaned.csv (12 rows)\n",
      "Saved: DATAMA2_SYLLABUS_2nd_Term_2024_version3.0_cleaned.csv (12 rows)\n",
      "Saved: DESALGO_Syllabus_2024_cleaned.csv (7 rows)\n",
      "Saved: ENTJAVA (Using C# .NET) Course Syllabus 2023-2024_cleaned.csv (11 rows)\n",
      "Saved: ICTSRV1_Syllabus_2024_cleaned.csv (15 rows)\n",
      "Saved: INFOSEC_Syllabus_2023_cleaned.csv (13 rows)\n",
      "Saved: INFOSEC_Syllabus_T1_AY_2024_2025_cleaned.csv (13 rows)\n",
      "Saved: INPROLA Syllabus 2ndTerm_2024ver3.0_cleaned.csv (8 rows)\n",
      "Saved: INPROLA Syllabus Revision T1 A.Y. 2023 Revise Oct 2023_cleaned.csv (9 rows)\n",
      "Saved: INPROLA Syllabus T1 A.Y. 2024-2025 Revise version_cleaned.csv (18 rows)\n",
      "Saved: INTCOMC_Syllabus 2024-2025_cleaned.csv (13 rows)\n",
      "Saved: INTSDEV_Syllabus_2023-2024_cleaned.csv (7 rows)\n",
      "Saved: ITCONCE_SYLLABUS_AY2023-2024 - Revise Oct 2023_cleaned.csv (13 rows)\n",
      "Saved: MCSPROJ Course Syllabus AY2024-2025 for IT_cleaned.csv (3 rows)\n",
      "Saved: MNSYSIT Course Syllabus AY 2024-2025_cleaned.csv (4 rows)\n",
      "Saved: MNSYSIT Salesforce_AY 2023-2024 v2_cleaned.csv (4 rows)\n",
      "Saved: MNSYSIT Salesforce_T1 AY 2024-2025 for upload_cleaned.csv (2 rows)\n",
      "Saved: MNTSDEV-SNTSDEV-INTSDEV Course Syllabus 2023 - 2024_cleaned.csv (7 rows)\n",
      "Saved: MNTSDEV-SNTSDEV-INTSDEV Course Syllabus AY 2024 - 2025 v2_cleaned.csv (6 rows)\n",
      "Saved: MOBAPPL  Syllabus T2 A.Y. 2024-2025 Revise version_cleaned.csv (14 rows)\n",
      "Saved: MOBPROG Course Syllabus 1T 2022 - Revise Oct 2023_cleaned.csv (16 rows)\n",
      "Saved: MOBPROG Course Syllabus 1T 2024-2025 Revise version_cleaned.csv (16 rows)\n",
      "Saved: MODESIM_Syllabus_2024_cleaned.csv (11 rows)\n",
      "Saved: NETDESM_2024_cleaned.csv (13 rows)\n",
      "Saved: OPESYST_SYLLABUS_AY2024-2025_cleaned.csv (18 rows)\n",
      "Saved: PROGCON Syllabus Revision  T1 A.Y. 2023-2024 Revise Oct 2023_cleaned.csv (15 rows)\n",
      "Saved: PROGCON_SYLLABUS_2024_1stTerm_version_cleaned.csv (9 rows)\n",
      "Saved: PROGCON_SYLLABUS_2ndTerm_2024_3.0_cleaned.csv (9 rows)\n",
      "Saved: PROJMAN AY 2023_2024 Syllabus_cleaned.csv (10 rows)\n",
      "Saved: PROJMAN _Syllabus_T1 AY 2024-2025_cleaned.csv (14 rows)\n",
      "Saved: QUALITY_SYLLABUS_2023 for CS_cleaned.csv (12 rows)\n",
      "Saved: QUALITY_SYLLABUS_AY_2023_2024 for IT_cleaned.csv (12 rows)\n",
      "Saved: SCSPROJ - MCSPROJ Course Syllabus AY 2023 - 2024_cleaned.csv (3 rows)\n",
      "Saved: SCSPROJ Course Syllabus AY2024-2025 for CS_cleaned.csv (3 rows)\n",
      "Saved: Softdev Syllabus 2023 - 2024 for CS and IT_cleaned.csv (10 rows)\n",
      "Saved: SOFTDEV_Syllabus_T1_AY_ 2024_2025_for_CS_and _T_cleaned.csv (10 rows)\n",
      "Saved: SSYADD1-MSYADD1_Syllabus_2023_cleaned.csv (6 rows)\n",
      "Saved: SSYADD1-MSYADD1_Syllabus_T1 AY 2024-2025_cleaned.csv (14 rows)\n",
      "Saved: THESIS2 2023 Syllabus  T1 AY 2024 2025_cleaned.csv (10 rows)\n",
      "Saved: USERDES Course Syllabus 1T 2020_cleaned.csv (13 rows)\n",
      "Saved: WEBPROG_Syllabus_2023_2024_cleaned.csv (13 rows)\n",
      "Saved: WEBPSEC_Syllabus_2024_cleaned.csv (13 rows)\n",
      "----------------------------------------\n",
      "Individual file saving completed\n",
      "Saved 57 files to: cleaned_csv\n",
      "\n",
      "First 5 saved files:\n",
      "  1. AUTOMAT_SYLLABUS_2ndTerm_2024_ver3.0_cleaned.csv\n",
      "  2. CLDCOMP_Syllabus 2023-2024_cleaned.csv\n",
      "  3. CLDSRV2_Syllabus 2023_2024_cleaned.csv\n",
      "  4. CLDSRV2_Syllabus_2024_cleaned.csv\n",
      "  5. COMPORG_SYLLABUS_AY2024_2025_cleaned.csv\n",
      "  ... and 52 more files\n",
      "\n",
      "Individual file saving completed\n"
     ]
    }
   ],
   "source": [
    "def save_individual_files(dataframes_list, original_files_list, output_directory):\n",
    "    \"\"\"Save each cleaned DataFrame as an individual CSV file.\"\"\"\n",
    "    saved_files = []\n",
    "    \n",
    "    print(f\"Saving {len(dataframes_list)} cleaned CSV files...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for df, original_file_path in zip(dataframes_list, original_files_list):\n",
    "        try:\n",
    "            # Create output filename\n",
    "            original_name = Path(original_file_path).stem\n",
    "            cleaned_filename = f\"{original_name}_cleaned.csv\"\n",
    "            output_path = Path(output_directory) / cleaned_filename\n",
    "            \n",
    "            # Save the file\n",
    "            df.to_csv(output_path, index=False)\n",
    "            saved_files.append(str(output_path))\n",
    "            \n",
    "            print(f\"Saved: {cleaned_filename} ({len(df)} rows)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving {os.path.basename(original_file_path)}: {str(e)}\")\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "# Save individual cleaned files\n",
    "if all_dataframes:\n",
    "    saved_individual_files = save_individual_files(all_dataframes, processed_files, OUTPUT_DIRECTORY)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Individual file saving completed\")\n",
    "    print(f\"Saved {len(saved_individual_files)} files to: {OUTPUT_DIRECTORY}\")\n",
    "    \n",
    "    # Show first few saved files\n",
    "    print(f\"\\nFirst 5 saved files:\")\n",
    "    for i, saved_file in enumerate(saved_individual_files[:5]):\n",
    "        print(f\"  {i+1}. {os.path.basename(saved_file)}\")\n",
    "    \n",
    "    if len(saved_individual_files) > 5:\n",
    "        print(f\"  ... and {len(saved_individual_files) - 5} more files\")\n",
    "        \n",
    "else:\n",
    "    print(\"No dataframes to save - check previous steps for errors\")\n",
    "\n",
    "print(\"\\nIndividual file saving completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d59606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined dataset from 57 files...\n",
      "Sorted by source file\n",
      "Combined dataset saved to: combined_csv\\combined_cleaned_syllabi_data.csv\n",
      "Total rows in combined dataset: 584\n",
      "Columns: ['Learning Outcomes', 'Deliverables', 'Assessments', 'Source_File', 'Course_Code']\n",
      "\n",
      "Rows per source file:\n",
      "  Total unique files: 57\n",
      "  Average rows per file: 10.2\n",
      "  Min rows per file: 1\n",
      "  Max rows per file: 18\n",
      "\n",
      "Top 10 files by row count:\n",
      "  1. INPROLA Syllabus T1 A.Y. 2024-2025 Revise version.csv: 18 rows\n",
      "  2. OPESYST_SYLLABUS_AY2024-2025.csv: 18 rows\n",
      "  3. MOBPROG Course Syllabus 1T 2024-2025 Revise version.csv: 16 rows\n",
      "  4. MOBPROG Course Syllabus 1T 2022 - Revise Oct 2023.csv: 16 rows\n",
      "  5. ICTSRV1_Syllabus_2024.csv: 15 rows\n",
      "  6. PROGCON Syllabus Revision  T1 A.Y. 2023-2024 Revise Oct 2023.csv: 15 rows\n",
      "  7. SSYADD1-MSYADD1_Syllabus_T1 AY 2024-2025.csv: 14 rows\n",
      "  8. PROJMAN _Syllabus_T1 AY 2024-2025.csv: 14 rows\n",
      "  9. MOBAPPL  Syllabus T2 A.Y. 2024-2025 Revise version.csv: 14 rows\n",
      "  10. INTCOMC_Syllabus 2024-2025.csv: 13 rows\n",
      "\n",
      "Data quality summary:\n",
      "  Learning Outcomes: 576/584 (98.6%) non-empty\n",
      "  Deliverables: 472/584 (80.8%) non-empty\n",
      "  Assessments: 562/584 (96.2%) non-empty\n",
      "\n",
      "Combined dataset creation completed\n",
      "File location: combined_csv\\combined_cleaned_syllabi_data.csv\n",
      "\n",
      "Combined dataset ready\n"
     ]
    }
   ],
   "source": [
    "def create_combined_dataset(dataframes_list, output_directory, filename=\"combined_cleaned_syllabi_data.csv\"):\n",
    "    \"\"\"Combine all cleaned DataFrames into a single CSV file.\"\"\"\n",
    "    \n",
    "    if not dataframes_list:\n",
    "        print(\"No dataframes to combine\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Creating combined dataset from {len(dataframes_list)} files...\")\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "    \n",
    "    # Sort by source file for better organization\n",
    "    if 'Source_File' in combined_df.columns:\n",
    "        combined_df = combined_df.sort_values('Source_File').reset_index(drop=True)\n",
    "        print(\"Sorted by source file\")\n",
    "    \n",
    "    # Create output path\n",
    "    output_path = Path(output_directory) / filename\n",
    "    \n",
    "    # Save combined file\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Combined dataset saved to: {output_path}\")\n",
    "    print(f\"Total rows in combined dataset: {len(combined_df)}\")\n",
    "    print(f\"Columns: {list(combined_df.columns)}\")\n",
    "    \n",
    "    # Show summary by source file\n",
    "    if 'Source_File' in combined_df.columns:\n",
    "        file_counts = combined_df['Source_File'].value_counts()\n",
    "        print(f\"\\nRows per source file:\")\n",
    "        print(f\"  Total unique files: {len(file_counts)}\")\n",
    "        print(f\"  Average rows per file: {file_counts.mean():.1f}\")\n",
    "        print(f\"  Min rows per file: {file_counts.min()}\")\n",
    "        print(f\"  Max rows per file: {file_counts.max()}\")\n",
    "        \n",
    "        print(f\"\\nTop 10 files by row count:\")\n",
    "        for i, (filename, count) in enumerate(file_counts.head(10).items()):\n",
    "            print(f\"  {i+1}. {filename}: {count} rows\")\n",
    "    \n",
    "    # Show data quality summary\n",
    "    print(f\"\\nData quality summary:\")\n",
    "    for col in ['Learning Outcomes', 'Deliverables', 'Assessments']:\n",
    "        if col in combined_df.columns:\n",
    "            non_empty = combined_df[col].str.len() > 0\n",
    "            non_empty_count = non_empty.sum()\n",
    "            percentage = (non_empty_count / len(combined_df)) * 100\n",
    "            print(f\"  {col}: {non_empty_count}/{len(combined_df)} ({percentage:.1f}%) non-empty\")\n",
    "    \n",
    "    return str(output_path)\n",
    "\n",
    "# Create combined dataset\n",
    "if all_dataframes:\n",
    "    combined_file_path = create_combined_dataset(\n",
    "        all_dataframes, \n",
    "        COMBINED_OUTPUT_DIR, \n",
    "        \"combined_cleaned_syllabi_data.csv\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCombined dataset creation completed\")\n",
    "    print(f\"File location: {combined_file_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No dataframes available for combining\")\n",
    "\n",
    "print(\"\\nCombined dataset ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ae19fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "INPUT:\n",
      "  Source directory: csv_outputs\n",
      "  Total CSV files found: 58\n",
      "\n",
      "PROCESSING RESULTS:\n",
      "  Successfully processed: 57\n",
      "  Failed to process: 1\n",
      "  Success rate: 98.3%\n",
      "  Total rows extracted: 584\n",
      "  Average rows per file: 10.2\n",
      "\n",
      "OUTPUT:\n",
      "  Individual cleaned files: cleaned_csv\n",
      "    Number of files: 57\n",
      "  Combined dataset: combined_csv\n",
      "    Combined file rows: 584\n",
      "    Combined file columns: ['Learning Outcomes', 'Deliverables', 'Assessments', 'Source_File', 'Course_Code']\n",
      "\n",
      "FAILED FILES:\n",
      "  1. course_outline.csv\n",
      "\n",
      "HEADER MAPPING USED:\n",
      "  Learning Outcomes:\n",
      "    - Learning Outcomes\n",
      "    - Learning Outcome\n",
      "    - Learning\\nOutcomes\n",
      "    - ... and 5 more variations\n",
      "  Deliverables:\n",
      "    - Deliverables Outcomes\n",
      "    - Deliverables/Outcomes\n",
      "    - Deliverables\n",
      "    - ... and 7 more variations\n",
      "  Assessments:\n",
      "    - Assessments\n",
      "    - Assessment\n",
      "    - Assessment Task\n",
      "    - ... and 1 more variations\n",
      "============================================================\n",
      "PROCESS COMPLETED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "VALIDATION:\n",
      "------------------------------\n",
      "Individual cleaned files: 57 found\n",
      "Combined file: EXISTS\n",
      "  Shape: (584, 5)\n",
      "  All required columns present: ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
      "  Data completeness:\n",
      "    Learning Outcomes: 584/584 (100.0%) non-empty\n",
      "    Deliverables: 584/584 (100.0%) non-empty\n",
      "    Assessments: 584/584 (100.0%) non-empty\n",
      "------------------------------\n",
      "Validation completed\n",
      "\n",
      "============================================================\n",
      "ALL STEPS COMPLETED\n",
      "============================================================\n",
      "\n",
      "Your cleaned data is ready:\n",
      "1. Individual files: cleaned_csv\n",
      "2. Combined file: combined_csv/combined_cleaned_syllabi_data.csv\n"
     ]
    }
   ],
   "source": [
    "def generate_final_summary():\n",
    "    \"\"\"Generate a comprehensive summary of the entire process.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"FINAL PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Input summary\n",
    "    print(f\"\\nINPUT:\")\n",
    "    print(f\"  Source directory: {INPUT_CSV_DIRECTORY}\")\n",
    "    csv_files = find_csv_files(INPUT_CSV_DIRECTORY)\n",
    "    print(f\"  Total CSV files found: {len(csv_files)}\")\n",
    "    \n",
    "    # Processing summary\n",
    "    print(f\"\\nPROCESSING RESULTS:\")\n",
    "    print(f\"  Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"  Failed to process: {len(failed_files)}\")\n",
    "    print(f\"  Success rate: {(len(processed_files)/len(csv_files)*100):.1f}%\")\n",
    "    \n",
    "    if all_dataframes:\n",
    "        total_rows = sum(len(df) for df in all_dataframes)\n",
    "        print(f\"  Total rows extracted: {total_rows}\")\n",
    "        print(f\"  Average rows per file: {total_rows/len(all_dataframes):.1f}\")\n",
    "    \n",
    "    # Output summary\n",
    "    print(f\"\\nOUTPUT:\")\n",
    "    print(f\"  Individual cleaned files: {OUTPUT_DIRECTORY}\")\n",
    "    if all_dataframes:\n",
    "        print(f\"    Number of files: {len(all_dataframes)}\")\n",
    "    \n",
    "    print(f\"  Combined dataset: {COMBINED_OUTPUT_DIR}\")\n",
    "    \n",
    "    # Check if combined file exists and get its info\n",
    "    combined_file = Path(COMBINED_OUTPUT_DIR) / \"combined_cleaned_syllabi_data.csv\"\n",
    "    if combined_file.exists():\n",
    "        try:\n",
    "            combined_df = pd.read_csv(combined_file)\n",
    "            print(f\"    Combined file rows: {len(combined_df)}\")\n",
    "            print(f\"    Combined file columns: {list(combined_df.columns)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Error reading combined file: {e}\")\n",
    "    \n",
    "    # Failed files details\n",
    "    if failed_files:\n",
    "        print(f\"\\nFAILED FILES:\")\n",
    "        for i, failed_file in enumerate(failed_files, 1):\n",
    "            print(f\"  {i}. {os.path.basename(failed_file)}\")\n",
    "    \n",
    "    # Header mapping summary\n",
    "    print(f\"\\nHEADER MAPPING USED:\")\n",
    "    for canonical, variations in HEADER_MAPPING.items():\n",
    "        print(f\"  {canonical}:\")\n",
    "        for variation in variations[:3]:  # Show first 3 variations\n",
    "            print(f\"    - {variation}\")\n",
    "        if len(variations) > 3:\n",
    "            print(f\"    - ... and {len(variations)-3} more variations\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"PROCESS COMPLETED SUCCESSFULLY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "def validate_output():\n",
    "    \"\"\"Validate the output files.\"\"\"\n",
    "    \n",
    "    print(\"\\nVALIDATION:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Check individual files\n",
    "    individual_files = glob.glob(os.path.join(OUTPUT_DIRECTORY, \"*_cleaned.csv\"))\n",
    "    print(f\"Individual cleaned files: {len(individual_files)} found\")\n",
    "    \n",
    "    # Check combined file\n",
    "    combined_file = Path(COMBINED_OUTPUT_DIR) / \"combined_cleaned_syllabi_data.csv\"\n",
    "    if combined_file.exists():\n",
    "        print(f\"Combined file: EXISTS\")\n",
    "        \n",
    "        # Quick validation of combined file\n",
    "        try:\n",
    "            df_combined = pd.read_csv(combined_file)\n",
    "            print(f\"  Shape: {df_combined.shape}\")\n",
    "            \n",
    "            # Check required columns\n",
    "            required_cols = ['Learning Outcomes', 'Deliverables', 'Assessments']\n",
    "            missing_cols = [col for col in required_cols if col not in df_combined.columns]\n",
    "            \n",
    "            if missing_cols:\n",
    "                print(f\"  Warning: Missing columns: {missing_cols}\")\n",
    "            else:\n",
    "                print(f\"  All required columns present: {required_cols}\")\n",
    "            \n",
    "            # Check data completeness\n",
    "            print(f\"  Data completeness:\")\n",
    "            for col in required_cols:\n",
    "                if col in df_combined.columns:\n",
    "                    non_empty = (df_combined[col].astype(str).str.len() > 0) & (df_combined[col] != 'nan')\n",
    "                    count = non_empty.sum()\n",
    "                    percent = (count / len(df_combined)) * 100\n",
    "                    print(f\"    {col}: {count}/{len(df_combined)} ({percent:.1f}%) non-empty\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error validating combined file: {e}\")\n",
    "    else:\n",
    "        print(f\"Combined file: NOT FOUND\")\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(\"Validation completed\")\n",
    "\n",
    "# Generate final summary\n",
    "generate_final_summary()\n",
    "\n",
    "# Validate output\n",
    "validate_output()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL STEPS COMPLETED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nYour cleaned data is ready:\")\n",
    "print(f\"1. Individual files: {OUTPUT_DIRECTORY}\")\n",
    "print(f\"2. Combined file: {COMBINED_OUTPUT_DIR}/combined_cleaned_syllabi_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
